{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8a762cdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.0.1 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\traitlets\\config\\application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelapp.py\", line 701, in start\n",
      "    self.io_loop.start()\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\tornado\\platform\\asyncio.py\", line 205, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\asyncio\\windows_events.py\", line 322, in run_forever\n",
      "    super().run_forever()\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\asyncio\\base_events.py\", line 641, in run_forever\n",
      "    self._run_once()\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\asyncio\\base_events.py\", line 1987, in _run_once\n",
      "    handle._run()\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\asyncio\\events.py\", line 88, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 534, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 523, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 429, in dispatch_shell\n",
      "    await result\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 767, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 429, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\ipykernel\\zmqshell.py\", line 549, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3075, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3130, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3334, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3517, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3577, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_10944\\2829019913.py\", line 6, in <module>\n",
      "    import pandas as pd\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\pandas\\__init__.py\", line 26, in <module>\n",
      "    from pandas.compat import (\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\pandas\\compat\\__init__.py\", line 27, in <module>\n",
      "    from pandas.compat.pyarrow import (\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\pandas\\compat\\pyarrow.py\", line 8, in <module>\n",
      "    import pyarrow as pa\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\pyarrow\\__init__.py\", line 65, in <module>\n",
      "    import pyarrow.lib as _lib\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "\nA module that was compiled using NumPy 1.x cannot be run in\nNumPy 2.0.1 as it may crash. To support both 1.x and 2.x\nversions of NumPy, modules must be compiled with NumPy 2.0.\nSome module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n\nIf you are a user of the module, the easiest solution will be to\ndowngrade to 'numpy<2' or try to upgrade the affected module.\nWe expect that some modules will need time to support NumPy 2.\n\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\numpy\\core\\_multiarray_umath.py:44\u001b[0m, in \u001b[0;36m__getattr__\u001b[1;34m(attr_name)\u001b[0m\n\u001b[0;32m     39\u001b[0m     \u001b[38;5;66;03m# Also print the message (with traceback).  This is because old versions\u001b[39;00m\n\u001b[0;32m     40\u001b[0m     \u001b[38;5;66;03m# of NumPy unfortunately set up the import to replace (and hide) the\u001b[39;00m\n\u001b[0;32m     41\u001b[0m     \u001b[38;5;66;03m# error.  The traceback shouldn't be needed, but e.g. pytest plugins\u001b[39;00m\n\u001b[0;32m     42\u001b[0m     \u001b[38;5;66;03m# seem to swallow it and we should be failing anyway...\u001b[39;00m\n\u001b[0;32m     43\u001b[0m     sys\u001b[38;5;241m.\u001b[39mstderr\u001b[38;5;241m.\u001b[39mwrite(msg \u001b[38;5;241m+\u001b[39m tb_msg)\n\u001b[1;32m---> 44\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(msg)\n\u001b[0;32m     46\u001b[0m ret \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(_multiarray_umath, attr_name, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m     47\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ret \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mImportError\u001b[0m: \nA module that was compiled using NumPy 1.x cannot be run in\nNumPy 2.0.1 as it may crash. To support both 1.x and 2.x\nversions of NumPy, modules must be compiled with NumPy 2.0.\nSome module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n\nIf you are a user of the module, the easiest solution will be to\ndowngrade to 'numpy<2' or try to upgrade the affected module.\nWe expect that some modules will need time to support NumPy 2.\n\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.0.1 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\traitlets\\config\\application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelapp.py\", line 701, in start\n",
      "    self.io_loop.start()\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\tornado\\platform\\asyncio.py\", line 205, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\asyncio\\windows_events.py\", line 322, in run_forever\n",
      "    super().run_forever()\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\asyncio\\base_events.py\", line 641, in run_forever\n",
      "    self._run_once()\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\asyncio\\base_events.py\", line 1987, in _run_once\n",
      "    handle._run()\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\asyncio\\events.py\", line 88, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 534, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 523, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 429, in dispatch_shell\n",
      "    await result\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 767, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 429, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\ipykernel\\zmqshell.py\", line 549, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3075, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3130, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3334, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3517, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3577, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_10944\\2829019913.py\", line 6, in <module>\n",
      "    import pandas as pd\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\pandas\\__init__.py\", line 49, in <module>\n",
      "    from pandas.core.api import (\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\pandas\\core\\api.py\", line 1, in <module>\n",
      "    from pandas._libs import (\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\pandas\\_libs\\__init__.py\", line 17, in <module>\n",
      "    import pandas._libs.pandas_datetime  # noqa: F401 # isort: skip # type: ignore[reportUnusedImport]\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "\nA module that was compiled using NumPy 1.x cannot be run in\nNumPy 2.0.1 as it may crash. To support both 1.x and 2.x\nversions of NumPy, modules must be compiled with NumPy 2.0.\nSome module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n\nIf you are a user of the module, the easiest solution will be to\ndowngrade to 'numpy<2' or try to upgrade the affected module.\nWe expect that some modules will need time to support NumPy 2.\n\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\numpy\\core\\_multiarray_umath.py:44\u001b[0m, in \u001b[0;36m__getattr__\u001b[1;34m(attr_name)\u001b[0m\n\u001b[0;32m     39\u001b[0m     \u001b[38;5;66;03m# Also print the message (with traceback).  This is because old versions\u001b[39;00m\n\u001b[0;32m     40\u001b[0m     \u001b[38;5;66;03m# of NumPy unfortunately set up the import to replace (and hide) the\u001b[39;00m\n\u001b[0;32m     41\u001b[0m     \u001b[38;5;66;03m# error.  The traceback shouldn't be needed, but e.g. pytest plugins\u001b[39;00m\n\u001b[0;32m     42\u001b[0m     \u001b[38;5;66;03m# seem to swallow it and we should be failing anyway...\u001b[39;00m\n\u001b[0;32m     43\u001b[0m     sys\u001b[38;5;241m.\u001b[39mstderr\u001b[38;5;241m.\u001b[39mwrite(msg \u001b[38;5;241m+\u001b[39m tb_msg)\n\u001b[1;32m---> 44\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(msg)\n\u001b[0;32m     46\u001b[0m ret \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(_multiarray_umath, attr_name, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m     47\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ret \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mImportError\u001b[0m: \nA module that was compiled using NumPy 1.x cannot be run in\nNumPy 2.0.1 as it may crash. To support both 1.x and 2.x\nversions of NumPy, modules must be compiled with NumPy 2.0.\nSome module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n\nIf you are a user of the module, the easiest solution will be to\ndowngrade to 'numpy<2' or try to upgrade the affected module.\nWe expect that some modules will need time to support NumPy 2.\n\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "numpy.core.multiarray failed to import",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 6\u001b[0m\n\u001b[0;32m      3\u001b[0m warnings\u001b[38;5;241m.\u001b[39mfilterwarnings(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[0;32m      8\u001b[0m get_ipython()\u001b[38;5;241m.\u001b[39mrun_line_magic(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmatplotlib\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124minline\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\__init__.py:49\u001b[0m\n\u001b[0;32m     46\u001b[0m \u001b[38;5;66;03m# let init-time option registration happen\u001b[39;00m\n\u001b[0;32m     47\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconfig_init\u001b[39;00m  \u001b[38;5;66;03m# pyright: ignore[reportUnusedImport] # noqa: F401\u001b[39;00m\n\u001b[1;32m---> 49\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     50\u001b[0m     \u001b[38;5;66;03m# dtype\u001b[39;00m\n\u001b[0;32m     51\u001b[0m     ArrowDtype,\n\u001b[0;32m     52\u001b[0m     Int8Dtype,\n\u001b[0;32m     53\u001b[0m     Int16Dtype,\n\u001b[0;32m     54\u001b[0m     Int32Dtype,\n\u001b[0;32m     55\u001b[0m     Int64Dtype,\n\u001b[0;32m     56\u001b[0m     UInt8Dtype,\n\u001b[0;32m     57\u001b[0m     UInt16Dtype,\n\u001b[0;32m     58\u001b[0m     UInt32Dtype,\n\u001b[0;32m     59\u001b[0m     UInt64Dtype,\n\u001b[0;32m     60\u001b[0m     Float32Dtype,\n\u001b[0;32m     61\u001b[0m     Float64Dtype,\n\u001b[0;32m     62\u001b[0m     CategoricalDtype,\n\u001b[0;32m     63\u001b[0m     PeriodDtype,\n\u001b[0;32m     64\u001b[0m     IntervalDtype,\n\u001b[0;32m     65\u001b[0m     DatetimeTZDtype,\n\u001b[0;32m     66\u001b[0m     StringDtype,\n\u001b[0;32m     67\u001b[0m     BooleanDtype,\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# missing\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     NA,\n\u001b[0;32m     70\u001b[0m     isna,\n\u001b[0;32m     71\u001b[0m     isnull,\n\u001b[0;32m     72\u001b[0m     notna,\n\u001b[0;32m     73\u001b[0m     notnull,\n\u001b[0;32m     74\u001b[0m     \u001b[38;5;66;03m# indexes\u001b[39;00m\n\u001b[0;32m     75\u001b[0m     Index,\n\u001b[0;32m     76\u001b[0m     CategoricalIndex,\n\u001b[0;32m     77\u001b[0m     RangeIndex,\n\u001b[0;32m     78\u001b[0m     MultiIndex,\n\u001b[0;32m     79\u001b[0m     IntervalIndex,\n\u001b[0;32m     80\u001b[0m     TimedeltaIndex,\n\u001b[0;32m     81\u001b[0m     DatetimeIndex,\n\u001b[0;32m     82\u001b[0m     PeriodIndex,\n\u001b[0;32m     83\u001b[0m     IndexSlice,\n\u001b[0;32m     84\u001b[0m     \u001b[38;5;66;03m# tseries\u001b[39;00m\n\u001b[0;32m     85\u001b[0m     NaT,\n\u001b[0;32m     86\u001b[0m     Period,\n\u001b[0;32m     87\u001b[0m     period_range,\n\u001b[0;32m     88\u001b[0m     Timedelta,\n\u001b[0;32m     89\u001b[0m     timedelta_range,\n\u001b[0;32m     90\u001b[0m     Timestamp,\n\u001b[0;32m     91\u001b[0m     date_range,\n\u001b[0;32m     92\u001b[0m     bdate_range,\n\u001b[0;32m     93\u001b[0m     Interval,\n\u001b[0;32m     94\u001b[0m     interval_range,\n\u001b[0;32m     95\u001b[0m     DateOffset,\n\u001b[0;32m     96\u001b[0m     \u001b[38;5;66;03m# conversion\u001b[39;00m\n\u001b[0;32m     97\u001b[0m     to_numeric,\n\u001b[0;32m     98\u001b[0m     to_datetime,\n\u001b[0;32m     99\u001b[0m     to_timedelta,\n\u001b[0;32m    100\u001b[0m     \u001b[38;5;66;03m# misc\u001b[39;00m\n\u001b[0;32m    101\u001b[0m     Flags,\n\u001b[0;32m    102\u001b[0m     Grouper,\n\u001b[0;32m    103\u001b[0m     factorize,\n\u001b[0;32m    104\u001b[0m     unique,\n\u001b[0;32m    105\u001b[0m     value_counts,\n\u001b[0;32m    106\u001b[0m     NamedAgg,\n\u001b[0;32m    107\u001b[0m     array,\n\u001b[0;32m    108\u001b[0m     Categorical,\n\u001b[0;32m    109\u001b[0m     set_eng_float_format,\n\u001b[0;32m    110\u001b[0m     Series,\n\u001b[0;32m    111\u001b[0m     DataFrame,\n\u001b[0;32m    112\u001b[0m )\n\u001b[0;32m    114\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdtypes\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdtypes\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SparseDtype\n\u001b[0;32m    116\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtseries\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m infer_freq\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\api.py:1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_libs\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m      2\u001b[0m     NaT,\n\u001b[0;32m      3\u001b[0m     Period,\n\u001b[0;32m      4\u001b[0m     Timedelta,\n\u001b[0;32m      5\u001b[0m     Timestamp,\n\u001b[0;32m      6\u001b[0m )\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_libs\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmissing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m NA\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdtypes\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdtypes\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     10\u001b[0m     ArrowDtype,\n\u001b[0;32m     11\u001b[0m     CategoricalDtype,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     14\u001b[0m     PeriodDtype,\n\u001b[0;32m     15\u001b[0m )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\_libs\\__init__.py:17\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# Below imports needs to happen first to ensure pandas top level\u001b[39;00m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# module gets monkeypatched with the pandas_datetime_CAPI\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# see pandas_datetime_exec in pd_datetime.c\u001b[39;00m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_libs\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpandas_parser\u001b[39;00m  \u001b[38;5;66;03m# isort: skip # type: ignore[reportUnusedImport]\u001b[39;00m\n\u001b[1;32m---> 17\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_libs\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpandas_datetime\u001b[39;00m  \u001b[38;5;66;03m# noqa: F401 # isort: skip # type: ignore[reportUnusedImport]\u001b[39;00m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_libs\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minterval\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Interval\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_libs\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtslibs\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     20\u001b[0m     NaT,\n\u001b[0;32m     21\u001b[0m     NaTType,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     26\u001b[0m     iNaT,\n\u001b[0;32m     27\u001b[0m )\n",
      "\u001b[1;31mImportError\u001b[0m: numpy.core.multiarray failed to import"
     ]
    }
   ],
   "source": [
    "# Import Libraries\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "\n",
    "pd.set_option('display.max_rows', 100)\n",
    "pd.set_option('display.max_columns', 100)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from scipy import stats\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# evaluation metrics\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import roc_curve, auc, precision_recall_curve \n",
    "\n",
    "# models\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# Hyper parameter tuning\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# model explainability\n",
    "from sklearn.tree import export_graphviz\n",
    "import shap\n",
    "import graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14836323",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('Targeting_right_customer.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22c6eb0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data1=data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27fd4c07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset Rows & Columns count\n",
    "print(\"Dataset consist \", data1.shape[0],\" rows and \",data1.shape[1],\"columns.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "494f84eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset Info\n",
    "data1.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ed70619",
   "metadata": {},
   "outputs": [],
   "source": [
    "data1.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c7b89a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset Duplicate Value Count\n",
    "data1[data1.duplicated()].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58504081",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Missing Values/Null Values Count\n",
    "data1.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07d107c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data1.isnull().sum().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0bd99a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "high_null=data1.isnull().sum()/len(data)\n",
    "high_null.sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79a731f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data1=data1.drop([\"Asymmetrique Activity Index\",\"Asymmetrique Profile Score\",\"Asymmetrique Activity Score\",\"Asymmetrique Profile Index\"],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78151989",
   "metadata": {},
   "outputs": [],
   "source": [
    "data1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17c9f4bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# no. of unique variables\n",
    "for i in data1.select_dtypes(\"O\").columns:\n",
    "    print('Column name :',i)\n",
    "    print(data1[i].unique())\n",
    "    print('Number of unique values : ',data1[i].nunique())\n",
    "    print()\n",
    "    print('*'*75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7a1d0c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data1=data1.drop([\"Prospect ID\",\"Lead Number\"],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6d55e67",
   "metadata": {},
   "outputs": [],
   "source": [
    "data1=data1.replace(\"Select\",np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25e67fed",
   "metadata": {},
   "outputs": [],
   "source": [
    "data1.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38313331",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in data1.select_dtypes(\"O\").columns:\n",
    "    print('Column name :',i)\n",
    "    print(data1[i].value_counts())\n",
    "    print()\n",
    "    print('*'*75)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3a9eb38",
   "metadata": {},
   "outputs": [],
   "source": [
    "data1[\"Lead Origin\"].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76149853",
   "metadata": {},
   "outputs": [],
   "source": [
    "data1[\"Lead Quality\"].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2561b1cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "Lead_data=data1[\"Lead Quality\"].value_counts().reset_index()\n",
    "Lead_data.columns=[\"Lead Quality\",\"count\"]\n",
    "\n",
    "sns.barplot(x=\"Lead Quality\",y=\"count\",data=Lead_data)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6594907",
   "metadata": {},
   "source": [
    "#### we are not sure about the client lead quality , we should handle the missing with Not Sure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ac20ad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data1[\"Lead Quality\"]=data1[\"Lead Quality\"].replace(np.nan,\"Not Sure\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a91b2ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "country_data=data1[\"Country\"].value_counts().reset_index()\n",
    "country_data.columns=[\"Country\",\"count\"]\n",
    "plt.xticks(rotation=90)\n",
    "sns.barplot(x=\"Country\",y=\"count\",data=country_data)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09bf68ff",
   "metadata": {},
   "source": [
    "#### the country column has 95% data from India."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "785c3ed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#city\n",
    "city_data=data1[\"City\"].value_counts().reset_index()\n",
    "city_data.columns=[\"City\",\"count\"]\n",
    "plt.xticks(rotation=90)\n",
    "sns.barplot(x=\"City\",y=\"count\",data=city_data)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e991d16c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"City\"].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c957fa6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data1[\"City\"]=data1[\"City\"].replace(np.nan,\"Mumbai\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5047fef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#specialization\n",
    "city_data=data1[\"Specialization\"].value_counts().reset_index()\n",
    "city_data.columns=[\"Specialization\",\"count\"]\n",
    "plt.xticks(rotation=90)\n",
    "sns.barplot(x=\"Specialization\",y=\"count\",data=city_data)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a626e19f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data1[\"Specialization\"].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3128448f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data1[\"Specialization\"]=data1[\"Specialization\"].replace(np.nan,\"Others\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ea5771c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data1.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f44536a",
   "metadata": {},
   "outputs": [],
   "source": [
    "high_null1=data1.isnull().sum()/len(data)\n",
    "high_null1.sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de29819b",
   "metadata": {},
   "outputs": [],
   "source": [
    "high_missing=high_null1[high_null1>0.70].index\n",
    "high_missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94dcdf98",
   "metadata": {},
   "outputs": [],
   "source": [
    "data1=data1.drop(high_missing,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87e7a69f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data1.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3059395",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tags\n",
    "city_data=data1[\"Tags\"].value_counts().reset_index()\n",
    "city_data.columns=[\"Tags\",\"count\"]\n",
    "plt.xticks(rotation=90)\n",
    "sns.barplot(x=\"Tags\",y=\"count\",data=city_data)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d53f0aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "data1[\"Tags\"]=data1[\"Tags\"].replace(np.nan,\"No comments\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06a3610a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#What is your current occupation\n",
    "city_data=data[\"What is your current occupation\"].value_counts().reset_index()\n",
    "city_data.columns=[\"What is your current occupation\",\"count\"]\n",
    "plt.xticks(rotation=90)\n",
    "sns.barplot(x=\"What is your current occupation\",y=\"count\",data=city_data)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "181d6f26",
   "metadata": {},
   "outputs": [],
   "source": [
    "data1[\"What is your current occupation\"]=data1[\"What is your current occupation\"].replace(np.nan,\"Other\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b36b13f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#What matters most to you in choosing a course\n",
    "city_data=data1[\"What matters most to you in choosing a course\"].value_counts().reset_index()\n",
    "city_data.columns=[\"What matters most to you in choosing a course\",\"count\"]\n",
    "plt.xticks(rotation=90)\n",
    "sns.barplot(x=\"What matters most to you in choosing a course\",y=\"count\",data=city_data)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ae7aaa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data1[\"What matters most to you in choosing a course\"]=data1[\"What matters most to you in choosing a course\"].replace(np.nan,\"Other\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63661474",
   "metadata": {},
   "outputs": [],
   "source": [
    "data1[\"Country\"]=data1[\"Country\"].replace(np.nan,\"India\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc489256",
   "metadata": {},
   "outputs": [],
   "source": [
    "(data1.isnull().sum()/len(data)*100).sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "032cf1ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "data1=data1.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b9888c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data1.isnull().sum().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f95aef08",
   "metadata": {},
   "source": [
    "# Univariate Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2036ac31",
   "metadata": {},
   "outputs": [],
   "source": [
    "data1.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c7cd174",
   "metadata": {},
   "outputs": [],
   "source": [
    "data1[\"Converted\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66926d56",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(data1[\"Converted\"])\n",
    "print(data1['Converted'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbf77213",
   "metadata": {},
   "outputs": [],
   "source": [
    "# value_count function to find univariant columns\n",
    "for i in data1.select_dtypes(\"O\").columns:\n",
    "    print(\"#######################  \\n\")\n",
    "    print(i)\n",
    "    print(\"\\n\")\n",
    "    print(data1[i].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "726ce843",
   "metadata": {},
   "outputs": [],
   "source": [
    "data2=data1.drop([\"Do Not Call\",\"Country\",\"What matters most to you in choosing a course\",\"Search\",\n",
    "                    \"Magazine\",\"Newspaper Article\",\"X Education Forums\",\"Newspaper\",\"Digital Advertisement\",\n",
    "                   \"Through Recommendations\",\"Receive More Updates About Our Courses\",\n",
    "                   \"Update me on Supply Chain Content\",\"Get updates on DM Content\",\"I agree to pay the amount through cheque\",\n",
    "                   ],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c0e0edd",
   "metadata": {},
   "outputs": [],
   "source": [
    "data2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e74a7a9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data2.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c98e323b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data2=data1.drop([\"Do Not Call\",\"Country\",\"What matters most to you in choosing a course\",\"Search\",\n",
    "                    \"Magazine\",\"Newspaper Article\",\"X Education Forums\",\"Newspaper\",\"Digital Advertisement\",\n",
    "                   \"Through Recommendations\",\"Receive More Updates About Our Courses\",\n",
    "                   \"Update me on Supply Chain Content\",\"Get updates on DM Content\",\"I agree to pay the amount through cheque\",\n",
    "                   ],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8e79c8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(1)\n",
    "plt.figure(figsize= (15,8))\n",
    "plt.subplot(221)\n",
    "sns.countplot(data2['Lead Origin'])\n",
    "plt.xticks(rotation=90)\n",
    "plt.subplot(222)\n",
    "sns.countplot(x=data2['Lead Origin'],hue = data2['Converted'])\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13d3fd24",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(1)\n",
    "plt.figure(figsize= (15,8))\n",
    "plt.subplot(221)\n",
    "sns.countplot(data2['Lead Source'])\n",
    "plt.xticks(rotation=90)\n",
    "plt.subplot(222)\n",
    "sns.countplot(x=data2['Lead Source'],hue = data2['Converted'])\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca0845ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(1)\n",
    "plt.figure(figsize= (15,8))\n",
    "plt.subplot(221)\n",
    "sns.countplot(data2['Tags'])\n",
    "plt.xticks(rotation=90)\n",
    "plt.subplot(222)\n",
    "sns.countplot(x=data2['Tags'],hue = data2['Converted'])\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6ca6660",
   "metadata": {},
   "outputs": [],
   "source": [
    "data2[\"Tags\"]=data2[\"Tags\"].replace([\"invalid number\",\"Diploma holder (Not Eligible)\",\"wrong number given\",\n",
    "                                       \"opp hangup\",\"number not provided\",\"in touch with EINS\",\"Lost to Others\",\n",
    "                                       \"Still Thinking\",\"Want to take admission but has financial problems\",\n",
    "                                       \"In confusion whether part time or DLP\",\"Interested in Next batch\",\n",
    "                                       \"Lateral student\",\"Shall take in the next coming month\",\n",
    "                                       \"University not recognized\",\"Recognition issue (DEC approval)\",\n",
    "                                       \"Graduation in progress\"],\"OTHER_COMMENT\")\n",
    "                                       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8566781d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data2.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4226648c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(1)\n",
    "plt.figure(figsize= (15,8))\n",
    "plt.subplot(221)\n",
    "sns.countplot(data2['Tags'])\n",
    "plt.xticks(rotation=90)\n",
    "plt.subplot(222)\n",
    "sns.countplot(x=data2['Tags'],hue = data2['Converted'])\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c114d138",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in data2.columns:\n",
    "    plt.figure(1)\n",
    "    plt.figure(figsize= (15,8))\n",
    "    plt.subplot(221)\n",
    "    sns.countplot(data2[i])\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.subplot(222)\n",
    "    sns.countplot(x=data2[i],hue = data2['Converted'])\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acc39618",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # map to convert two category column\n",
    "# data2[\"Do Not Email\"]=data2[\"Do Not Email\"].map({\"Yes\":1,\"No\":0})\n",
    "# data2[\"A free copy of Mastering The Interview\"]=data2[\"A free copy of Mastering The Interview\"].map({\"Yes\":1,\"No\":0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "213bffa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets see the correlation matrix\n",
    "corr_matrix=data2.corr(method=\"spearman\")\n",
    "sns.heatmap(corr_matrix,annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2e3773a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data2.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b39ffa3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data2.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1b50ef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model building process\n",
    "X=data2.drop([\"Converted\"],axis=1)\n",
    "Y=data2[\"Converted\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c37ebeda",
   "metadata": {},
   "outputs": [],
   "source": [
    "trf1 = ColumnTransformer(transformers =[ \n",
    "    ('scaler', MinMaxScaler(), [\"TotalVisits\",\"Total Time Spent on Website\",\"Page Views Per Visit\"]), \n",
    "    ('ohe', OneHotEncoder(sparse = False, drop ='first'), [\"Lead Origin\",\"Lead Source\",\"Last Activity\",\"Specialization\",\n",
    "                              \"What is your current occupation\",\"Tags\",\"Lead Quality\",\"City\",\"Do Not Email\",\n",
    "                              \"Last Notable Activity\",\"A free copy of Mastering The Interview\",]),      \n",
    "], remainder ='passthrough')\n",
    "prepro_pipeline = Pipeline(steps=[(\"trf1\", trf1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9c36c2a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_scaled = prepro_pipeline.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c46a7fbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_scaled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3296b31c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "joblib.dump(prepro_pipeline, 'prepro_pipeline.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1e07c43",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation_matrix(y_train_pred, y_test_pred, y_train,y_test):\n",
    "    '''\n",
    "    This function take predicted and actual value and return the various evaluation metric along with the confusion matrix plot\n",
    "    '''\n",
    "    # (1)  calculating the train and test roc_auc score\n",
    "    train_roc_auc = roc_auc_score(y_train,y_train_pred)\n",
    "    test_roc_auc = roc_auc_score(y_test,y_test_pred)\n",
    "    print(\" The train and test roc_auc score are \" ,train_roc_auc, \" and \",test_roc_auc)\n",
    "\n",
    "    # (2) calculating train and test precision score\n",
    "    train_precision = precision_score(y_train, y_train_pred)\n",
    "    test_precision = precision_score(y_test,y_test_pred)\n",
    "    print(\" The train and test precision score are \" ,train_precision, \" and \",test_precision)\n",
    "\n",
    "    # (3) calculating train and test recall score\n",
    "    train_recall = recall_score(y_train, y_train_pred)\n",
    "    test_recall = recall_score(y_test,y_test_pred)\n",
    "    print(\" The train and test Recall score are \" ,train_recall, \" and \",test_recall)\n",
    "\n",
    "    # (4) calculating the train and test accuracy score\n",
    "    train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "    test_accuracy = accuracy_score(y_test,y_test_pred)\n",
    "    print(\" The train and test Accuracy score are \" ,train_accuracy, \" and \",test_accuracy)\n",
    "    \n",
    "    # (5) calculating the train and test f1 score\n",
    "    train_f1_score = f1_score(y_train, y_train_pred)\n",
    "    test_f1_score = f1_score(y_test,y_test_pred)\n",
    "    print(\" The train and test f1 score are \" ,train_f1_score, \" and \",test_f1_score)\n",
    "\n",
    "    # (6) plotting the confusion matrix\n",
    "    train_confusion_matrix = confusion_matrix(y_train, y_train_pred)\n",
    "    test_confusion_matrix = confusion_matrix(y_test,y_test_pred)\n",
    "    plt.figure(1)\n",
    "    plt.figure(figsize=(25,10))\n",
    "\n",
    "    ax= plt.subplot(331)\n",
    "    sns.heatmap(train_confusion_matrix, annot = True, fmt ='d', ax = ax)\n",
    "    ax.set_xlabel('Predicted labels');ax.set_ylabel('True labels');\n",
    "    ax.set_ylim(2.0, 0)\n",
    "    ax.set_title('Train Confusion Matrix');\n",
    "    ax.xaxis.set_ticklabels(['0','1']);\n",
    "    ax.yaxis.set_ticklabels(['0','1']);\n",
    "\n",
    "    ax= plt.subplot(332)\n",
    "    sns.heatmap(test_confusion_matrix, annot = True, fmt ='d', ax = ax)\n",
    "    ax.set_xlabel('Predicted labels');ax.set_ylabel('True labels');\n",
    "    ax.set_ylim(2.0, 0)\n",
    "    ax.set_title('Test Confusion Matrix');\n",
    "    ax.xaxis.set_ticklabels(['0','1']);\n",
    "    ax.yaxis.set_ticklabels(['0','1']);\n",
    "\n",
    "    # (6) plot the train and test roc plot\n",
    "    train_fpr, train_tpr, tr_thresholds = roc_curve(y_train, y_train_pred)\n",
    "    test_fpr, test_tpr, te_thresholds = roc_curve(y_test, y_test_pred)\n",
    "\n",
    "    train_AUC_bow = auc(train_fpr, train_tpr)\n",
    "    test_AUC_bow = auc(test_fpr, test_tpr)\n",
    "\n",
    "    plt.subplot(333)\n",
    "    plt.plot(train_fpr, train_tpr, label=\"train AUC =\"+str(train_AUC_bow))\n",
    "    plt.plot(test_fpr, test_tpr, label=\"test AUC =\"+str(test_AUC_bow))\n",
    "    plt.plot([0, 1], [0, 1], 'k--')\n",
    "    plt.legend()\n",
    "    plt.xlabel(\"False positive rate: FPR\")\n",
    "    plt.ylabel(\"True positive rate: TPR\")\n",
    "    plt.title(\"ERROR PLOTS\")\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "    return train_roc_auc,test_roc_auc, train_accuracy,test_accuracy, test_precision, test_recall\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e31486ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def threshold(Y_train,y_proba_log):\n",
    "    precision,recall,thresholds=precision_recall_curve(Y_train,y_proba_log[:,1])\n",
    "    f1_scores=2*(precision*recall)/(precision+recall)\n",
    "    optimal_idx=np.argmax(f1_scores)\n",
    "    optimal_threshold=thresholds[optimal_idx]\n",
    "    print(\" The optimal_threshold value is \" ,optimal_threshold)\n",
    "    return optimal_threshold\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bc901ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting the data into training testing\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,Y_train,Y_test=train_test_split(X_scaled,Y,train_size=0.8,random_state=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11cfaacc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ML Model - 1 Implementation\n",
    "def LogisticRegressionModel(x_train,x_test,y_train):\n",
    "    '''\n",
    "    This function trains the logistic regression model and return the predicted train and test value\n",
    "    '''\n",
    "\n",
    "    logistic = LogisticRegression()  # default value of C = 1.0\n",
    "    # Fit the Algorithm\n",
    "    logistic.fit(x_train,y_train)\n",
    "    # Predict on the model\n",
    "    y_train_pred_log = logistic.predict(x_train)\n",
    "    y_test_pred_log = logistic.predict(x_test)\n",
    "    y_proba_log = logistic.predict_proba(x_train)\n",
    "    return y_train_pred_log,y_test_pred_log,y_proba_log,logistic\n",
    "\n",
    "y_train_pred_log,y_test_pred_log,y_proba_log,LR = LogisticRegressionModel(X_train,X_test,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73386889",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_roc_auc_log,test_roc_auc_log, train_accuracy_log,test_accuracy_log, test_precision_log, test_recall_log= evaluation_matrix(y_train_pred_log, y_test_pred_log, Y_train,Y_test)\n",
    "logistic_thresholds = threshold(Y_train,y_proba_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9bb5b1c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# ML Model - 1 Implementation with hyperparameter optimization techniques (i.e., GridSearch CV, RandomSearch CV, Bayesian Optimization etc.)\n",
    "\n",
    "# c is the hyper parameter for logistic regression\n",
    "parameter = {'C' : [10**i for i in range(-3,3)]}\n",
    "\n",
    "# calling the estimator\n",
    "logistic = LogisticRegression()\n",
    "\n",
    "# GridSearchCV\n",
    "Gslr = GridSearchCV\n",
    "Gslr = GridSearchCV(estimator = logistic,param_grid = parameter,scoring ='recall', refit = True, return_train_score = True,cv=5)\n",
    "\n",
    "# Fit the Algorithm\n",
    "Gslr.fit(X_train,Y_train)\n",
    "\n",
    "# plotting the train and test score for various hyperparameter\n",
    "result = pd.DataFrame(Gslr.cv_results_)\n",
    "plt.plot(result['param_C'],result['mean_train_score'],'r',label = 'train_score')\n",
    "plt.plot(result['param_C'],result['mean_test_score'],'y',label ='test_score')\n",
    "plt.xlabel('Hyperparameter')\n",
    "plt.ylabel('score')\n",
    "plt.title('Score vs hyperparameter')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Predict on the model\n",
    "y_train_pred_log_gs = Gslr.predict(X_train)\n",
    "y_test_pred_log_gs = Gslr.predict(X_test)\n",
    "y_proba_log_gs = Gslr.predict_proba(X_train)\n",
    "\n",
    "#print best alpha\n",
    "print(Gslr.best_params_)\n",
    "print('*** Scores from the best model ***')\n",
    "# evaluation metrics\n",
    "train_roc_auc_log_gs,test_roc_auc_log_gs, train_accuracy_log_gs,test_accuracy_log_gs, test_precision_log_gs, test_recall_log_gs = evaluation_matrix(y_train_pred_log_gs, y_test_pred_log_gs, Y_train,Y_test)\n",
    "logistic_gs_thresholds = threshold(Y_train,y_proba_log_gs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2c5c943",
   "metadata": {},
   "outputs": [],
   "source": [
    "def MultinomialNaiveBayes(x_train,x_test,y_train):\n",
    "    '''\n",
    "    This function trains the  Multinomial Naive Bayes model and return the predicted train and test value\n",
    "    '''\n",
    "\n",
    "    mnbc = MultinomialNB(fit_prior=True)   # the default value of alpha = 1\n",
    "    # Fit the Algorithm\n",
    "    mnbc.fit(x_train,y_train)\n",
    "    # Predict on the model\n",
    "    y_train_pred_nb = mnbc.predict(x_train)\n",
    "    y_test_pred_nb = mnbc.predict(x_test)\n",
    "    y_proba_nb = mnbc.predict_proba(x_train)\n",
    "    return y_train_pred_nb,y_test_pred_nb,y_proba_nb,mnbc\n",
    "\n",
    "y_train_pred_nb,y_test_pred_nb,y_proba_nb,NB = MultinomialNaiveBayes(X_train,X_test,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f23569cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_roc_auc_nb,test_roc_auc_nb, train_accuracy_nb,test_accuracy_nb, test_precision_nb, test_recall_nb= evaluation_matrix(y_train_pred_nb,y_test_pred_nb, Y_train,Y_test)\n",
    "mnbc_thresholds = threshold(Y_train,y_proba_nb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b2bd796",
   "metadata": {},
   "outputs": [],
   "source": [
    "# c is the hyper parameter for logistic regression\n",
    "parameter = {'alpha' : [0.00001,0.0005, 0.0001,0.005,0.001,0.05,0.01,0.1,0.5,1,5,10,50,100]}\n",
    "\n",
    "# calling the estimator\n",
    "clf = MultinomialNB(fit_prior=True)\n",
    "\n",
    "# GridSearchCV\n",
    "Gsnb = GridSearchCV(estimator = clf,param_grid = parameter,scoring ='recall', refit = True, return_train_score = True, cv=5)\n",
    "\n",
    "# Fit the Algorithm\n",
    "Gsnb.fit(X_train,Y_train)\n",
    "\n",
    "# plotting the train and test score for various hyperparameter\n",
    "result = pd.DataFrame(Gsnb.cv_results_)\n",
    "plt.plot(result['param_alpha'],result['mean_train_score'],'r',label = 'train_score')\n",
    "plt.plot(result['param_alpha'],result['mean_test_score'],'y',label ='test_score')\n",
    "plt.xlabel('Hyperparameter')\n",
    "plt.ylabel('score')\n",
    "plt.title('Score vs alpha')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Predict on the model\n",
    "y_train_pred_nb_gs = Gsnb.predict(X_train)\n",
    "y_test_pred_nb_gs = Gsnb.predict(X_test)\n",
    "y_proba_nb_gs = Gsnb.predict_proba(X_train)\n",
    "\n",
    "#print best alpha\n",
    "print(Gsnb.best_params_)\n",
    "print('*** Scores from the best model ***')\n",
    "# evaluation metrics\n",
    "train_roc_auc_nb_gs,test_roc_auc_nb_gs, train_accuracy_nb_gs,test_accuracy_nb_gs, test_precision_nb_gs, test_recall_nb_gs = evaluation_matrix(y_train_pred_nb_gs, y_test_pred_nb_gs, Y_train,Y_test)\n",
    "mnbc_gs_thresholds = threshold(Y_train,y_proba_nb_gs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15b2ac00",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decisiontrees(x_train,x_test,y_train):\n",
    "    '''\n",
    "    This function trains the  Decision Tree Classifier model and return the predicted train and test value\n",
    "    '''\n",
    "\n",
    "    dtc = DecisionTreeClassifier(max_depth = 8,random_state = 42)   # for max_depth = none model was highly overfitting , so use a random depth = 8.\n",
    "\n",
    "    # Fit the Algorithm\n",
    "    dtc.fit(x_train,y_train)\n",
    "    # Predict on the model\n",
    "    y_train_pred_dtc = dtc.predict(x_train)\n",
    "    y_test_pred_dtc = dtc.predict(x_test)\n",
    "    y_proba_dtc = dtc.predict_proba(x_train)\n",
    "    return y_train_pred_dtc,y_test_pred_dtc,y_proba_dtc,dtc\n",
    "\n",
    "y_train_pred_dtc,y_test_pred_dtc,y_proba_dtc,dtc = decisiontrees(X_train,X_test,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ffef99f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_roc_auc_dtc,test_roc_auc_dtc, train_accuracy_dtc,test_accuracy_dtc, test_precision_dtc, test_recall_dtc= evaluation_matrix(y_train_pred_dtc,y_test_pred_dtc, Y_train,Y_test)\n",
    "dtc_thresholds = threshold(Y_train,y_proba_dtc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c0fee46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# c is the hyper parameter for logistic regression\n",
    "parameter = {'max_depth' : [3,5,7,8], 'min_samples_split' : [100,200,250,300]}\n",
    "\n",
    "# calling the estimator\n",
    "dtc =  DecisionTreeClassifier(random_state = 42)\n",
    "\n",
    "# GridSearchCV\n",
    "Gsdtc = GridSearchCV(estimator =dtc, param_grid = parameter, scoring ='roc_auc', refit = True, return_train_score = True,cv=5)\n",
    "\n",
    "# Fit the Algorithm\n",
    "Gsdtc.fit(X_train,Y_train)\n",
    "\n",
    "# plotting the train and test score for various hyperparameter\n",
    "results = pd.DataFrame(Gsdtc.cv_results_)\n",
    "train_score_dt = results['mean_train_score']\n",
    "test_score_dt = results['mean_test_score']\n",
    "best_max_depth = results['param_max_depth']\n",
    "print(\"-\"*100)\n",
    "# Lets plot the results\n",
    "plt.figure(1)\n",
    "plt.figure(figsize=(25,10))\n",
    "\n",
    "#heatmap\n",
    "plt.subplot(331)\n",
    "dataset_train = results.pivot('param_max_depth', 'param_min_samples_split', 'mean_train_score')\n",
    "ax = sns.heatmap(dataset_train, annot=True)\n",
    "plt.title('train_score')\n",
    "\n",
    "plt.subplot(332)\n",
    "dataset_train = results.pivot('param_max_depth', 'param_min_samples_split', 'mean_test_score')\n",
    "ax = sns.heatmap(dataset_train, annot=True)\n",
    "plt.title('CV_score')\n",
    "\n",
    "plt.subplot(333)\n",
    "plt.plot(best_max_depth,train_score_dt,'r',label = 'train_score')\n",
    "plt.plot(best_max_depth,test_score_dt,'y',label ='test_score')\n",
    "plt.xlabel('depth')\n",
    "plt.ylabel('score')\n",
    "plt.title('score vs depth')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "print(\"-\"*200)\n",
    "print(\"The best parameters are:\",Gsdtc.best_params_)\n",
    "print(\"The scores on best parameters are:\")\n",
    "\n",
    "# Predict on the model\n",
    "y_train_pred_dtc_gs = Gsdtc.predict(X_train)\n",
    "y_test_pred_dtc_gs = Gsdtc.predict(X_test)\n",
    "y_proba_dtc_gs = Gsdtc.predict_proba(X_train)\n",
    "\n",
    "#print best alpha\n",
    "\n",
    "print('*** Scores from the best model ***')\n",
    "# evaluation metrics\n",
    "train_roc_auc_dtc_gs,test_roc_auc_dtc_gs, train_accuracy_dtc_gs,test_accuracy_dtc_gs, test_precision_dtc_gs, test_recall_dtc_gs = evaluation_matrix(y_train_pred_dtc_gs, y_test_pred_dtc_gs, Y_train,Y_test)\n",
    "dtc_gs_thresholds = threshold(Y_train,y_proba_dtc_gs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d0f5284",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Randomforest(x_train,x_test,y_train):\n",
    "    '''\n",
    "    This function trains the  Random forest Classifier model and return the predicted train and test value\n",
    "    '''\n",
    "\n",
    "    rfc = RandomForestClassifier(max_depth = 10, n_estimators = 200, min_samples_split = 100,random_state = 42)   # using the best hyperparameter obtained from decision trees with n_estimator =200\n",
    "\n",
    "    # Fit the Algorithm\n",
    "    rfc.fit(x_train,y_train)\n",
    "    # Predict on the model\n",
    "    y_train_pred_rfc = rfc.predict(x_train)\n",
    "    y_test_pred_rfc = rfc.predict(x_test)\n",
    "    y_proba_rfc = rfc.predict_proba(x_train)\n",
    "    return y_train_pred_rfc,y_test_pred_rfc,y_proba_rfc,rfc\n",
    "\n",
    "y_train_pred_rfc,y_test_pred_rfc,y_proba_rfc,rfc = Randomforest(X_train,X_test,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f671804",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_roc_auc_rfc,test_roc_auc_rfc, train_accuracy_rfc,test_accuracy_rfc, test_precision_rfc, test_recall_rfc = evaluation_matrix(y_train_pred_rfc, y_test_pred_rfc, Y_train,Y_test)\n",
    "rfc_thresholds = threshold(Y_train,y_proba_rfc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6723c081",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameter = {'max_depth' : [8,10,11,13], 'n_estimators':[100,150,200,250],'min_samples_split': [100,150,200,300]}\n",
    "\n",
    "rfc = RandomForestClassifier(random_state=42)\n",
    "\n",
    "rand_cv = RandomizedSearchCV(estimator = rfc, param_distributions = parameter,n_iter = 5, cv = 5,random_state= 42,n_jobs = -1,refit=True, return_train_score = True)\n",
    "rand_cv.fit(X_train,Y_train)\n",
    "print(rand_cv.best_estimator_)\n",
    "y_train_pred_cv_rf = rand_cv.predict(X_train)\n",
    "y_test_pred_cv_rf = rand_cv.predict(X_test)\n",
    "y_proba_cv_rf = rand_cv.predict_proba(X_train)\n",
    "\n",
    "train_roc_auc_rf_cv,test_roc_auc_rf_cv, train_accuracy_rf_cv,test_accuracy_rf_cv, test_precision_rf_cv, test_recall_rf_cv = evaluation_matrix(y_train_pred_cv_rf, y_test_pred_cv_rf, Y_train,Y_test)\n",
    "rfc_rand_cv_thresholds = threshold(Y_train,y_proba_cv_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23ae1cd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def XGboost(x_train,x_test,y_train):\n",
    "    '''\n",
    "    This function trains the  xgboost Classifier model and return the predicted train and test value\n",
    "    '''\n",
    "\n",
    "    xgb = XGBClassifier(max_depth = 3, n_estimators = 500, min_samples_split = 100,learning_rate = 0.05,random_state = 42)\n",
    "\n",
    "    # Fit the Algorithm\n",
    "    xgb.fit(X_train,Y_train)\n",
    "    # Predict on the model\n",
    "    y_train_pred_xgb = xgb.predict(x_train)\n",
    "    y_test_pred_xgb = xgb.predict(x_test)\n",
    "    y_proba_xgb = xgb.predict_proba(x_train)\n",
    "    return y_train_pred_xgb,y_test_pred_xgb,y_proba_xgb,xgb\n",
    "\n",
    "y_train_pred_xgb,y_test_pred_xgb,y_proba_xgb,xgb = XGboost(X_train,X_test,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17dfc66e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_roc_auc_xgb,test_roc_auc_xgb, train_accuracy_xgb,test_accuracy_xgb, test_precision_xgb, test_recall_xgb = evaluation_matrix(y_train_pred_xgb,y_test_pred_xgb, Y_train,Y_test)\n",
    "xgb_thresholds = threshold(Y_train,y_proba_xgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "936b8537",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgbc = XGBClassifier(random_state = 42)\n",
    "parameter = {'max_depth' : [1,2,3,4,5], 'n_estimators':[300,350,500,700],'min_samples_split': [50,100,150], 'learning_rate' :[0.05,0.07,0.1]}\n",
    "# using GridSearchCV will have 4*4*3*4 =192 models so will use RandomizedSearchCv for just 10 models to find the hyperparameter\n",
    "randx_cv = RandomizedSearchCV(estimator = xgbc, param_distributions = parameter, n_iter = 5,cv =5, refit = True,random_state= 42,n_jobs = -1, return_train_score = True)\n",
    "randx_cv.fit(X_train,Y_train)\n",
    "print(randx_cv.best_estimator_)\n",
    "y_train_pred_cv_xb = randx_cv.predict(X_train)\n",
    "y_test_pred_cv_xb = randx_cv.predict(X_test)\n",
    "y_proba_cv_xb = randx_cv.predict_proba(X_train)\n",
    "train_roc_auc_xb_cv,test_roc_auc_xb_cv, train_accuracy_xb_cv,test_accuracy_xb_cv, test_precision_xb_cv, test_recall_xb_cv = evaluation_matrix(y_train_pred_cv_xb, y_test_pred_cv_xb, Y_train,Y_test)\n",
    "randx_thresholds = threshold(Y_train,y_proba_cv_xb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dfcff57",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "def KNClassifier(x_train,x_test,y_train):\n",
    "    '''\n",
    "    This function trains the  Random forest Classifier model and return the predicted train and test value\n",
    "    '''\n",
    "\n",
    "    knc = KNeighborsClassifier()\n",
    "\n",
    "    # Fit the Algorithm\n",
    "    knc.fit(x_train,y_train)\n",
    "    # Predict on the model\n",
    "    y_train_pred_knc = knc.predict(x_train)\n",
    "    y_test_pred_knc = knc.predict(x_test)\n",
    "    y_proba_knc = knc.predict_proba(x_train)\n",
    "    return y_train_pred_knc,y_test_pred_knc,y_proba_knc,knc\n",
    "\n",
    "y_train_pred_knc,y_test_pred_knc,y_proba_knc,knc = KNClassifier(X_train,X_test,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9f8dae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_roc_auc_knc,test_roc_auc_knc, train_accuracy_knc,test_accuracy_knc, test_precision_knc, test_recall_knc = evaluation_matrix(y_train_pred_knc,y_test_pred_knc, Y_train,Y_test)\n",
    "knc_thresholds = threshold(Y_train,y_proba_knc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fecc934a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# c is the hyper parameter for logistic regression\n",
    "\n",
    "# define grid search\n",
    "parameter = { 'n_neighbors' : [5,7,9,11,13,15],\n",
    "               'weights' : ['uniform','distance'],\n",
    "               'metric' : ['minkowski','euclidean','manhattan']}\n",
    "\n",
    "# calling the estimator\n",
    "knc = KNeighborsClassifier()\n",
    "\n",
    "# GridSearchCV\n",
    "Gsknc = GridSearchCV(estimator =knc, param_grid = parameter, scoring ='roc_auc', refit = True, return_train_score = True,cv=5)\n",
    "\n",
    "# Fit the Algorithm\n",
    "Gsknc.fit(X_train,Y_train)\n",
    "\n",
    "print(\"-\"*200)\n",
    "print(\"The best parameters are:\",Gsknc.best_params_)\n",
    "print(\"The scores on best parameters are:\")\n",
    "\n",
    "# Predict on the model\n",
    "y_train_pred_knc_gs = Gsknc.predict(X_train)\n",
    "y_test_pred_knc_gs = Gsknc.predict(X_test)\n",
    "y_proba_knc_gs = Gsknc.predict_proba(X_train)\n",
    "\n",
    "#print best alpha\n",
    "\n",
    "print('*** Scores from the best model ***')\n",
    "# evaluation metrics\n",
    "train_roc_auc_knc_gs,test_roc_auc_knc_gs, train_accuracy_knc_gs,test_accuracy_knc_gs, test_precision_knc_gs, test_recall_knc_gs = evaluation_matrix(y_train_pred_knc_gs, y_test_pred_knc_gs, Y_train,Y_test)\n",
    "knc_gs_thresholds = threshold(Y_train,y_proba_knc_gs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3b95890",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"-\"*50,\"Models without hyperparameter tuning \",'-'*50)\n",
    "from prettytable import PrettyTable\n",
    "\n",
    "Table = PrettyTable()\n",
    "\n",
    "Table.field_names = [\"Model \",\"Threshold\",\"Train roc_auc\", \"Test roc_auc\", 'Train accuracy', 'Test accuracy', 'Test precision','Test Recall']\n",
    "Table.add_row([\"LogRegression\", round(logistic_thresholds,5),round(train_roc_auc_log,5), round(test_roc_auc_log,5),round(train_accuracy_log,5),round(test_accuracy_log,5),round(test_precision_log,5),round(test_recall_log,5)])\n",
    "Table.add_row([\"MultiNaiveBayes\",round(mnbc_thresholds,5),round(train_roc_auc_nb,5), round(test_roc_auc_nb,5),round(train_accuracy_nb,5),round(test_accuracy_nb,5),round(test_precision_nb,5),round(test_recall_nb,5)])\n",
    "Table.add_row([\"Decision tree \",round(dtc_thresholds,5), round(train_roc_auc_dtc,5), round(test_roc_auc_dtc,5),round(train_accuracy_dtc,5),round(test_accuracy_dtc,5),round(test_precision_dtc,5),round(test_recall_dtc,5)])\n",
    "Table.add_row([\"Random forest\", round(rfc_thresholds,5),round(train_roc_auc_rfc,5), round(test_roc_auc_rfc,5),round(train_accuracy_rfc,5),round(test_accuracy_rfc,5),round(test_precision_rfc,5),round(test_recall_rfc,5)])\n",
    "Table.add_row([\"KNClassifier\",round(knc_thresholds,5),round(train_roc_auc_knc,5), round(test_roc_auc_knc,5),round(train_accuracy_knc,5),round(test_accuracy_knc,5),round(test_precision_knc,5),round(test_recall_knc,5)])\n",
    "Table.add_row([\"Xgboost\",round(xgb_thresholds,5),round(train_roc_auc_xgb,5), round(test_roc_auc_xgb,5),round(train_accuracy_xgb,5),round(test_accuracy_xgb,5),round(test_precision_xgb,5),round(test_recall_xgb,5)])\n",
    "\n",
    "print(Table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c00c44bb",
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b254866c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"-\"*50,\"Models with hyperparameter tuning \",'-'*50)\n",
    "from prettytable import PrettyTable\n",
    "\n",
    "Table2 = PrettyTable()\n",
    "\n",
    "Table2.field_names = [\"Model \",\"Threshold\",\"Train roc_auc\", \"Test roc_auc\", 'Train accuracy', 'Test accuracy', 'Test precision','Test Recall']\n",
    "Table2.add_row([\"LogRegression\", round(logistic_gs_thresholds,5),round(train_roc_auc_log_gs,5), round(test_roc_auc_log_gs,5),round(train_accuracy_log_gs,5),round(test_accuracy_log_gs,5),round(test_precision_log_gs,5),round(test_recall_log_gs,5)])\n",
    "Table2.add_row([\"MultiNaiveBayes\",round(mnbc_gs_thresholds,5),round(train_roc_auc_nb_gs,5), round(test_roc_auc_nb_gs,5),round(train_accuracy_nb_gs,5),round(test_accuracy_nb_gs,5),round(test_precision_nb_gs,5),round(test_recall_nb_gs,5)])\n",
    "Table2.add_row([\"Decision tree \",round(dtc_gs_thresholds,5), round(train_roc_auc_dtc_gs,5), round(test_roc_auc_dtc_gs,5),round(train_accuracy_dtc_gs,5),round(test_accuracy_dtc_gs,5),round(test_precision_dtc_gs,5),round(test_recall_dtc_gs,5)])\n",
    "Table2.add_row([\"Random forest\", round(rfc_rand_cv_thresholds,5),round(train_roc_auc_rf_cv,5), round(test_roc_auc_rf_cv,5),round(train_accuracy_rf_cv,5),round(test_accuracy_rf_cv,5),round(test_precision_rf_cv,5),round(test_recall_rf_cv,5)])\n",
    "Table2.add_row([\"KNClassifier\",round(knc_gs_thresholds,5),round(train_roc_auc_knc_gs,5), round(test_roc_auc_knc_gs,5),round(train_accuracy_knc_gs,5),round(test_accuracy_knc_gs,5),round(test_precision_knc_gs,5),round(test_recall_knc_gs,5)])\n",
    "Table2.add_row([\"Xgboost\",round(randx_thresholds,5),round(train_roc_auc_xb_cv,5), round(test_roc_auc_xb_cv,5),round(train_accuracy_xb_cv,5),round(test_accuracy_xb_cv,5),round(test_precision_xb_cv,5),round(test_recall_xb_cv,5)])\n",
    "\n",
    "print(Table2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2de99608",
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(randx_cv, 'model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a283ba9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "xxx = pd.DataFrame(X_scaled)\n",
    "xxx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "202da839",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3a53c62",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83277ba5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff734d72",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28a07d34",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8d90031",
   "metadata": {},
   "outputs": [],
   "source": [
    "from prettytable import PrettyTable\n",
    "Table = PrettyTable()\n",
    "\n",
    "Table.field_names = [\"Model \",\"Threshold \",\"Train roc_auc\", \"Test roc_auc\", 'Train accuracy', 'Test accuracy', 'Test precision','Test Recall']\n",
    "Table.add_row([\"Log Regression\", round(train_roc_auc_log,6), round(test_roc_auc_log,6),round(train_accuracy_log,6),round(test_accuracy_log,6),round(test_precision_log,6),round(test_recall_log,6)])\n",
    "Table.add_row([\"Multi Naive Bayes\",round(train_roc_auc_nb,6), round(test_roc_auc_nb,6),round(train_accuracy_nb,6),round(test_accuracy_nb,6),round(test_precision_nb,6),round(test_recall_nb,6)])\n",
    "Table.add_row([\"Decision tree \", round(train_roc_auc_dtc,6), round(test_roc_auc_dtc,6),round(train_accuracy_dtc,6),round(test_accuracy_dtc,6),round(test_precision_dtc,6),round(test_recall_dtc,6)])\n",
    "Table.add_row([\"Random forest\", round(train_roc_auc_rf,6), round(test_roc_auc_rf,6),round(train_accuracy_rf,6),round(test_accuracy_rf,6),round(test_precision_rf,6),round(test_recall_rf,6)])\n",
    "Table.add_row([\"xgboost\",round(train_roc_auc_xb,6), round(test_roc_auc_xb,6),round(train_accuracy_xb,6),round(test_accuracy_xb,6),round(test_precision_xb,6),round(test_recall_xb,6)])\n",
    "\n",
    "\n",
    "print(Table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "851d5925",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb19e2bd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
